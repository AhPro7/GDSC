{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function, division\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout , BatchNormalization, Activation, ZeroPadding2D ,LeakyReLU ,UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "(training_data, _), (_, _) = fashion_mnist.load_data()\n",
    "X_train = training_data / 127.5 - 1.\n",
    "X_train = np.expand_dims(X_train, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD THE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    generator = Sequential()\n",
    "    generator.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=100))\n",
    "    generator.add(Reshape((7, 7, 128)))\n",
    "    generator.add(UpSampling2D())\n",
    "    generator.add(Conv2D(128, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    generator.add(UpSampling2D())\n",
    "\n",
    "    # We don’t add upsamplinghere because the image size of 28 × 28 is equal to the imagesize in the MNIST dataset. Youcan adjust this for yourown problem.\n",
    "    # convolutional + batch normalization layersgenerator.add(Conv2D(64, kernel_size=3, padding=\"same\",activation=\"relu\"))\n",
    "\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "    # convolutional layer with filters = 1\n",
    "    generator.add(Conv2D(1, kernel_size=3, padding=\"same\",activation=\"relu\")) # as output\n",
    "    generator.summary()\n",
    "    noise = Input(shape=(100,))\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    return Model(inputs=noise, outputs=fake_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build_discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Conv2D(32, kernel_size=3, strides=2,input_shape=(28,28,1), padding=\"same\"))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "    discriminator.add(Conv2D(64, kernel_size=3, strides=2,padding=\"same\"))\n",
    "    discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "\n",
    "    discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "\n",
    "    discriminator.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    discriminator.add(BatchNormalization(momentum=0.8))\n",
    "    discriminator.add(LeakyReLU(alpha=0.2))\n",
    "    discriminator.add(Dropout(0.25))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))#out put \n",
    "    img = Input(shape=(28,28,1))\n",
    "    probability = discriminator(img)\n",
    "    return Model(inputs=img, outputs=probability)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 6272)              633472    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 14, 14, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 14, 14, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 28, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 28, 28, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 1)         1153      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 783,233\n",
      "Trainable params: 782,721\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the generator\n",
    "generator = build_generator()\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "valid = discriminator(img)\n",
    "GAN = Model(inputs=z, outputs=valid)\n",
    "GAN.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples=100, dim=(10, 10),\n",
    "    figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(examples, 28, 28)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest',\n",
    "        cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('gan_generated_image_epoch_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    for epoch in range(epochs):\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        ## Train the combined network (Generator)\n",
    "        g_loss = GAN.train_on_batch(noise, valid)\n",
    "    print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "    if epoch % save_interval == 0:\n",
    "        plot_generated_images(epoch, generator)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epochs=1000, batch_size=32, save_interval=50)\n",
    "# allah with you "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Of Computer vision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
